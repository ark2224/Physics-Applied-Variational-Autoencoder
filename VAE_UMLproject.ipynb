{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "744e800f",
   "metadata": {},
   "source": [
    "Imports for necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c50d2c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import astropy.io.fits as fits\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import pywst as pw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14e9018",
   "metadata": {},
   "source": [
    "Below is the code for importing WST coefficients and RWST coefficients calculated using Thorne et al's methodology. These serve as data inputs for our VAE. The RWST's are downloaded solely for reference and are not used in comparison or loss calculation since VAE's are a typically unsupervised learning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95a75a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "wst_p = pickle.load(open('./wst_rwst_coeffs/WST_polarized_dust.p', 'rb'))\n",
    "rwst_p = pickle.load(open('./wst_rwst_coeffs/RWST_polarized_dust.p', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a438e9",
   "metadata": {},
   "source": [
    "# VAE with TensorFlow\n",
    "Imports for Tensorflow and test-training data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4192e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-05 15:29:24.049296: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from IPython import display\n",
    "\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670fd17e",
   "metadata": {},
   "source": [
    "Below is the preprocessing in which we take out the one S0 coefficient so the scaling between layers goes 1360->680->340->170 for VAE-1 and 1360->680->340->170->85 for VAE-2. Then the S0 coefficient is added back to have 171 (or 86) for OUR RWST coefficients. This preprocessing of preserving the S0 before and after the embedding was done similar to the past research paper Thorne et al."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3562a0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_wst, test_wst, train_rwst, test_rwst = train_test_split(wst_p, rwst_p, test_size=0.2, random_state=1)\n",
    "\n",
    "train_wst_s0 = train_wst[:,0]\n",
    "train_wst = train_wst[:,1:]\n",
    "\n",
    "test_wst_s0 = test_wst[:,0]\n",
    "test_wst = test_wst[:,1:]\n",
    "\n",
    "train_rwst_s0 = train_rwst[:,0]\n",
    "train_rwst = train_rwst[:,1:]\n",
    "\n",
    "test_rwst_s0 = test_rwst[:,0]\n",
    "test_rwst = test_rwst[:,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53094ee8",
   "metadata": {},
   "source": [
    "Below is the first Variational Autoencoder designed for this study. Its embedding in the latent space is in the 170th dimension. Its architecture is outlined in the written report. \n",
    "\n",
    "Underneath the VAE's initializer are four functions for operating the neural net. First is the \"sample\" function that takes a vector from a normal distribution in the input space. This vector can then be fed into the neural net to transform it into the latent space using the next function \"encode\". The \"encode\" function takes in one vector that should be of shape (1,1360) and feeds this vector into the neural net's encoder attribute that returns the vector's transformation into the latent space distribution with a mean and standard deviation. The function \"reparameterize\" calculates a specific vector z in the latent space from the calculated distribution returned by the \"encode\" function. The purpose of \"reparameterize\" is to take a sample vector from the latent space distribution to feed into the \"decode\" function and decode attribute to later backpropagate into the encoding and decoding functions. The last function is \"decode\" which is meant to take a sample vector from distributions in the latent space and decode them into the original input space. The purpose of this function is to transform vectors from latent to input space and calculate the loss between these decoded vectors and where they fall in the input data's distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc66d58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CVAE_1(tf.keras.Model):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(CVAE_1, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        input_shape=(1,1360,1)\n",
    "        self.encoder = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.InputLayer(input_shape=input_shape),\n",
    "                tf.keras.layers.Conv2D(\n",
    "                    filters=64,\n",
    "                    kernel_size=28, #decided by doing input_dim / 9; similar to keras documentation\n",
    "                    strides=2, \n",
    "#                     dilation_rate=2,\n",
    "                    padding='same',\n",
    "                    activation='relu', \n",
    "                    input_shape=(1,1360,1)), \n",
    "                tf.keras.layers.BatchNormalization(momentum=0.9), #layer 1 finish\n",
    "                tf.keras.layers.Conv2D(\n",
    "                    filters=32,\n",
    "                    kernel_size=14, \n",
    "                    strides=2, \n",
    "#                     dilation_rate=2,\n",
    "                    padding='same',\n",
    "                    activation='relu', \n",
    "                    input_shape=(1,680,64)),\n",
    "                tf.keras.layers.BatchNormalization(momentum=0.9), #layer 2 finish\n",
    "                tf.keras.layers.Conv2D(\n",
    "                    filters=1,\n",
    "                    kernel_size=7, \n",
    "                    strides=2,\n",
    "#                     dilation_rate=2,\n",
    "                    padding='same',\n",
    "                    activation='relu', \n",
    "                    input_shape=(1,340,32)),\n",
    "                tf.keras.layers.Reshape((1,1,170)),\n",
    "                tf.keras.layers.BatchNormalization(momentum=0.9), #layer 3 finish\n",
    "                tf.keras.layers.Flatten(),\n",
    "                tf.keras.layers.Dense(680),\n",
    "                tf.keras.layers.Dense(2*latent_dim)\n",
    "            ]\n",
    "        )\n",
    "        self.decoder = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.InputLayer(input_shape=(170)),\n",
    "                tf.keras.layers.Dense(5440),\n",
    "                tf.keras.layers.Reshape((1,170,32)),\n",
    "                tf.keras.layers.BatchNormalization(momentum=0.9),\n",
    "                tf.keras.layers.Conv2DTranspose(\n",
    "                    filters=128, \n",
    "                    strides=(1,2),\n",
    "                    kernel_size=14, \n",
    "                    padding='same',\n",
    "                    activation='relu',\n",
    "                    input_shape=(1,170,32)), #layer 1 finish\n",
    "                tf.keras.layers.BatchNormalization(momentum=0.9),\n",
    "                tf.keras.layers.Conv2DTranspose(\n",
    "                    filters=64, \n",
    "                    strides=1,\n",
    "                    kernel_size=14, \n",
    "                    padding='same',\n",
    "                    activation='relu',\n",
    "                    input_shape=(1,340,128)), #layer 2 finish\n",
    "                tf.keras.layers.BatchNormalization(momentum=0.9),\n",
    "                tf.keras.layers.Conv2DTranspose(\n",
    "                    filters=32, \n",
    "                    strides=(1,2),\n",
    "                    kernel_size=28, \n",
    "                    padding='same',\n",
    "                    activation='relu',\n",
    "                    input_shape=(1,340,64)), #layer 3 finish\n",
    "                tf.keras.layers.BatchNormalization(momentum=0.9),\n",
    "                tf.keras.layers.Conv2DTranspose(\n",
    "                    filters=16, \n",
    "                    strides=(1,2),\n",
    "                    kernel_size=56, \n",
    "                    padding='same',\n",
    "                    activation='relu',\n",
    "                    input_shape=(1,680,32)), #layer 4 finish\n",
    "                tf.keras.layers.BatchNormalization(momentum=0.9),\n",
    "                tf.keras.layers.Conv2DTranspose(\n",
    "                    filters=1, \n",
    "                    strides=1,\n",
    "                    kernel_size=56, \n",
    "                    padding='same',\n",
    "                    input_shape=(1,1360,1)) #layer 5 finish\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        \n",
    "    @tf.function\n",
    "    def sample(self, eps=None):\n",
    "        if eps is None:\n",
    "            eps = tf.random.normal(shape=(100,self.latent_dim))\n",
    "        return self.decode(eps, apply_sigmoid=True)\n",
    "    \n",
    "    def encode(self, x):\n",
    "#         print(self.encoder(x))\n",
    "        mean, logvar = tf.split(self.encoder(x), num_or_size_splits=2, axis=1)\n",
    "#         print(mean)\n",
    "#         print(logvar)\n",
    "        return mean, logvar\n",
    "    \n",
    "    def reparameterize(self, mean, logvar):\n",
    "        eps = tf.random.normal(shape=mean.shape)\n",
    "        return eps * tf.exp(logvar * 0.5) + mean\n",
    "    \n",
    "    def decode(self, z, apply_sigmoid=False):\n",
    "        logits = self.decoder(z)\n",
    "        if apply_sigmoid:\n",
    "            probs = tf.sigmoid(logits)\n",
    "            return probs\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c794965",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CVAE_2(tf.keras.Model):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(CVAE_2, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        input_shape = (1,1360,1)\n",
    "        self.encoder = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.InputLayer(input_shape=input_shape),\n",
    "                tf.keras.layers.Conv2D(\n",
    "                    filters=64,\n",
    "                    kernel_size=28,\n",
    "                    strides=2, \n",
    "                    padding='same',\n",
    "                    activation='relu', \n",
    "                    input_shape=(1,1360,1)), \n",
    "                tf.keras.layers.BatchNormalization(momentum=0.9), #layer 1 finish\n",
    "                tf.keras.layers.Conv2D(\n",
    "                    filters=32,\n",
    "                    kernel_size=14, \n",
    "                    strides=2, \n",
    "                    padding='same',\n",
    "                    activation='relu', \n",
    "                    input_shape=(1,680,64)),\n",
    "                tf.keras.layers.BatchNormalization(momentum=0.9), #layer 2 finish\n",
    "                tf.keras.layers.Conv2D(\n",
    "                    filters=16,\n",
    "                    kernel_size=7, \n",
    "                    strides=2,\n",
    "                    padding='same',\n",
    "                    activation='relu', \n",
    "                    input_shape=(1,340,32)),\n",
    "                tf.keras.layers.BatchNormalization(momentum=0.9), #layer 3 finish\n",
    "                tf.keras.layers.Conv2D(\n",
    "                    filters=1,\n",
    "                    kernel_size=7, \n",
    "                    strides=2,\n",
    "                    padding='same',\n",
    "                    activation='relu', \n",
    "                    input_shape=(1,170,16)), #layer 3 finish\n",
    "                tf.keras.layers.Reshape((1,1,85)),\n",
    "                tf.keras.layers.BatchNormalization(momentum=0.9), #layer 3 finish\n",
    "                tf.keras.layers.Flatten(),\n",
    "                tf.keras.layers.Dense(340),\n",
    "                tf.keras.layers.Dense(2*latent_dim)\n",
    "            ]\n",
    "        )\n",
    "        self.decoder = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.InputLayer(input_shape=(85)),\n",
    "                tf.keras.layers.Dense(2720),\n",
    "                tf.keras.layers.Reshape((1,85,32)),\n",
    "                tf.keras.layers.BatchNormalization(momentum=0.9),\n",
    "                tf.keras.layers.Conv2DTranspose(\n",
    "                    filters=128, \n",
    "                    strides=(1,2),\n",
    "                    kernel_size=14, \n",
    "                    padding='same',\n",
    "                    activation='relu',\n",
    "                    input_shape=(1,85,32)), #layer 1 finish\n",
    "                tf.keras.layers.BatchNormalization(momentum=0.9),\n",
    "                tf.keras.layers.Conv2DTranspose(\n",
    "                    filters=64, \n",
    "                    strides=(1,2), #only thing different than the CVAE_Large!\n",
    "                    kernel_size=14, \n",
    "                    padding='same',\n",
    "                    activation='relu',\n",
    "                    input_shape=(1,340,128)), #layer 2 finish\n",
    "                tf.keras.layers.BatchNormalization(momentum=0.9),\n",
    "                tf.keras.layers.Conv2DTranspose(\n",
    "                    filters=32, \n",
    "                    strides=(1,2),\n",
    "                    kernel_size=28, \n",
    "                    padding='same',\n",
    "                    activation='relu',\n",
    "                    input_shape=(1,340,64)), #layer 3 finish\n",
    "                tf.keras.layers.BatchNormalization(momentum=0.9),\n",
    "                tf.keras.layers.Conv2DTranspose(\n",
    "                    filters=16, \n",
    "                    strides=(1,2),\n",
    "                    kernel_size=56, \n",
    "                    padding='same',\n",
    "                    activation='relu',\n",
    "                    input_shape=(1,680,32)), #layer 4 finish\n",
    "                tf.keras.layers.BatchNormalization(momentum=0.9),\n",
    "                tf.keras.layers.Conv2DTranspose(\n",
    "                    filters=1, \n",
    "                    strides=1,\n",
    "                    kernel_size=56, \n",
    "                    padding='same',\n",
    "                    input_shape=(1,1360,1)) #layer 5 finish\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        \n",
    "        \n",
    "    @tf.function\n",
    "    def sample(self, eps=None):\n",
    "        if eps is None:\n",
    "            eps = tf.random.normal(shape=(100,self.latent_dim))\n",
    "        return self.decode(eps, apply_sigmoid=True)\n",
    "    \n",
    "    def encode(self, x):\n",
    "#         print(self.encoder(x))\n",
    "        mean, logvar = tf.split(self.encoder(x), num_or_size_splits=2, axis=1)\n",
    "        return mean, logvar\n",
    "    \n",
    "    def reparameterize(self, mean, logvar):\n",
    "        eps = tf.random.normal(shape=mean.shape)\n",
    "        return eps * tf.exp(logvar * 0.5) + mean\n",
    "    \n",
    "    def decode(self, z, apply_sigmoid=False):\n",
    "        logits = self.decoder(z)\n",
    "        if apply_sigmoid:\n",
    "            probs = tf.sigmoid(logits)\n",
    "            return probs\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b53fb9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = tf.random.normal(shape=(1,85))\n",
    "# test = tf.keras.Sequential(\n",
    "#             [\n",
    "#                 tf.keras.layers.InputLayer(input_shape=(85)),\n",
    "#                 tf.keras.layers.Dense(2720),\n",
    "#                 tf.keras.layers.Reshape((1,85,32)),\n",
    "#                 tf.keras.layers.BatchNormalization(momentum=0.9),\n",
    "#                 tf.keras.layers.Conv2DTranspose(\n",
    "#                     filters=128, \n",
    "#                     strides=(1,2),\n",
    "#                     kernel_size=14, \n",
    "#                     padding='same',\n",
    "#                     activation='relu',\n",
    "#                     input_shape=(1,85,32)), #layer 1 finish\n",
    "#                 tf.keras.layers.BatchNormalization(momentum=0.9),\n",
    "#                 tf.keras.layers.Conv2DTranspose(\n",
    "#                     filters=64, \n",
    "#                     strides=(1,2), #only thing different than the CVAE_Large!\n",
    "#                     kernel_size=14, \n",
    "#                     padding='same',\n",
    "#                     activation='relu',\n",
    "#                     input_shape=(1,340,128)), #layer 2 finish\n",
    "#                 tf.keras.layers.BatchNormalization(momentum=0.9),\n",
    "#                 tf.keras.layers.Conv2DTranspose(\n",
    "#                     filters=32, \n",
    "#                     strides=(1,2),\n",
    "#                     kernel_size=28, \n",
    "#                     padding='same',\n",
    "#                     activation='relu',\n",
    "#                     input_shape=(1,340,64)), #layer 3 finish\n",
    "#                 tf.keras.layers.BatchNormalization(momentum=0.9),\n",
    "#                 tf.keras.layers.Conv2DTranspose(\n",
    "#                     filters=16, \n",
    "#                     strides=(1,2),\n",
    "#                     kernel_size=56, \n",
    "#                     padding='same',\n",
    "#                     activation='relu',\n",
    "#                     input_shape=(1,680,32)), #layer 4 finish\n",
    "#                 tf.keras.layers.BatchNormalization(momentum=0.9),\n",
    "#                 tf.keras.layers.Conv2DTranspose(\n",
    "#                     filters=1, \n",
    "#                     strides=1,\n",
    "#                     kernel_size=56, \n",
    "#                     padding='same',\n",
    "#                     input_shape=(1,1360,1)) #layer 5 finish\n",
    "#             ]\n",
    "#         )\n",
    "# print(test(x).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88040cf2",
   "metadata": {},
   "source": [
    "Below are functions for calculating the loss and updating the neural net parameters with a given optimizer. The first function log_normal_pdf takes three parameters: a sample input vector, a mean, and log of the distribution's variance. Its purpose is to calculate the logarithmic probability of a vector under a certain distribution. The function \"compute_loss\" uses \"log_normal_pdf\" for calculating the total loss of the encoding and decoding process to update the neural net's parameters. For calculating the loss, this function calculates the ELBO loss: a sum of the the log probability of input vector x given latent vector z, the log probability of latent vector z in the latent space normal distribution, and the log probability of latent vector z given input vector x under the input data's distribution. Lastly, the \"train_step\" function takes one input vector and inputs it into the VAE to get one returned encoded-decoded vector. The function then computes the ELBO loss using \"compute_loss\" and uses the gradient of each of the VAE's parameters with respect to this loss to update the parameters themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee9b7f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "\n",
    "Output_var_VAE_L = []\n",
    "Latent_var_VAE_L = []\n",
    "Output_var_VAE_L = []\n",
    "Latent_var_VAE_S = []\n",
    "\n",
    "def log_normal_pdf(sample, mean, logvar, raxis=1):\n",
    "    log2pi = tf.math.log(2. * np.pi)\n",
    "    return tf.reduce_sum(-0.5 * ((sample - mean) ** 2. *tf.exp(-logvar) + logvar + log2pi), axis=raxis)\n",
    "\n",
    "def compute_loss(model, x, testing=False):\n",
    "    global Output_var_VAE_L, Output_var_VAE_L, Output_var_VAE_L, Latent_var_VAE_S\n",
    "    mean, logvar = model.encode(x)\n",
    "    z = model.reparameterize(mean, logvar)\n",
    "    x_logits = model.decode(z)\n",
    "    if testing:\n",
    "        if z.shape == (1, 170):\n",
    "            Latent_var_VAE_L.append(z)\n",
    "            Output_var_VAE_L.append(x_logits)\n",
    "        elif z.shape == (1, 85):\n",
    "            Latent_var_VAE_S.append(z)\n",
    "            Output_var_VAE_S.append(x_logits)\n",
    "    cross_ent = tf.nn.sigmoid_cross_entropy_with_logits(logits=x_logits, labels=x)\n",
    "    logpx_z = -tf.reduce_sum(cross_ent, axis=[1, 2, 3])\n",
    "    logpz = log_normal_pdf(z, 0., 0.)\n",
    "    logqz_x = log_normal_pdf(z, mean, logvar)\n",
    "    return -tf.reduce_mean(logpx_z + logpz - logqz_x)\n",
    "\n",
    "@tf.function\n",
    "def train_step(model, x, optimizer):\n",
    "#     executes one training step and returns loss\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = compute_loss(model, x)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff592145",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-05 15:29:51.209414: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "VAE_L = CVAE_1(170)\n",
    "VAE_S = CVAE_2(85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3040bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)\n",
    "# x = train_wst[0,:].astype(np.float32)\n",
    "# x = x.reshape(1, 1, 1360, 1)\n",
    "# train_step(VAE_S, x, optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43edb527",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "trainset_size = train_wst.shape[0]\n",
    "testset_size = test_wst.shape[0]\n",
    "for epoch in range(1, epochs + 1):\n",
    "    start_time = time.time()\n",
    "    for i in range(0,trainset_size):\n",
    "        x = train_wst[i,:].astype(np.float32)\n",
    "        x = x.reshape(1, 1, 1360, 1)\n",
    "        train_step(VAE_L, x, optimizer)\n",
    "    end_time = time.time()\n",
    "    print(\"finished training\")\n",
    "    loss = tf.keras.metrics.Mean()\n",
    "    for j in range(0,testset_size):\n",
    "        test_x = test_wst[j,:].astype(np.float32)\n",
    "        test_x = test_x.reshape(1, 1, 1360, 1)\n",
    "        loss(compute_loss(VAE_L, test_x, testing=True))\n",
    "    elbo = -loss.result()\n",
    "    display.clear_output(wait=False)\n",
    "    print('Epoch: {}, Test set ELBO: {}, time elapse for current epoch: {}'\n",
    "        .format(epoch, elbo, end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc997d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "trainset_size = train_wst.shape[0]\n",
    "testset_size = test_wst.shape[0]\n",
    "for epoch in range(1, epochs + 1):\n",
    "    start_time = time.time()\n",
    "    for i in range(0,trainset_size):\n",
    "        x = train_wst[i,:].astype(np.float32)\n",
    "        x = x.reshape(1, 1, 1360, 1)\n",
    "        train_step(VAE_S, x, optimizer)\n",
    "    end_time = time.time()\n",
    "    print(\"finished training\")\n",
    "    loss = tf.keras.metrics.Mean()\n",
    "    for j in range(0,testset_size):\n",
    "        test_x = test_wst[j,:].astype(np.float32)\n",
    "        test_x = test_x.reshape(1, 1, 1360, 1)\n",
    "        loss(compute_loss(VAE_S, test_x, testing=True))\n",
    "    elbo = -loss.result()\n",
    "    display.clear_output(wait=False)\n",
    "    print('Epoch: {}, Test set ELBO: {}, time elapse for current epoch: {}'\n",
    "        .format(epoch, elbo, end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0218a92e",
   "metadata": {},
   "source": [
    "WSTs outputted by the VAE's during testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0111cc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Stored_output_WSTs_from_testing:\\n VAE_L: \")\n",
    "print(Output_var_VAE_L)\n",
    "print(\"\\n VAE_S: \")\n",
    "print(Output_var_VAE_S)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f5908f",
   "metadata": {},
   "source": [
    "Latent space variables (z) found during testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f517449a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Stored_latent_space_variables_from_testing:\\n VAE_L: \")\n",
    "print(Latent_var_VAE_L)\n",
    "print(\"\\n VAE_S: \")\n",
    "print(Latent_var_VAE_S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59abe6e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "64b4507f",
   "metadata": {},
   "source": [
    "                            ================Scratchwork below====================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0116198",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CVAE_Large(tf.keras.Model):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(CVAE_Large, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.encoder = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.InputLayer(input_shape=(1,1360,1,1)),\n",
    "                tf.keras.layers.Conv2D(\n",
    "                    filters=128,\n",
    "                    kernel_size=28, #decided by doing input_dim / 9; similar to keras documentation\n",
    "                    strides=1, \n",
    "                    dilation_rate=2,\n",
    "                    padding='same',\n",
    "                    activation='relu'), \n",
    "                tf.keras.layers.BatchNormalization(momentum=0.9), #layer 1 finish\n",
    "                tf.keras.layers.Conv2D(\n",
    "                    filters=64,\n",
    "                    kernel_size=14, \n",
    "                    strides=1, \n",
    "                    dilation_rate=2,\n",
    "                    padding='same',\n",
    "                    activation='relu'),\n",
    "                tf.keras.layers.BatchNormalization(momentum=0.9), #layer 2 finish\n",
    "                tf.keras.layers.Conv2D(\n",
    "                    filters=32,\n",
    "                    kernel_size=7, \n",
    "                    strides=1,\n",
    "                    dilation_rate=2,\n",
    "                    padding='same',\n",
    "                    activation='relu'),\n",
    "                tf.keras.layers.BatchNormalization(momentum=0.9), #layer 3 finish\n",
    "                tf.keras.layers.Dense(680),\n",
    "                tf.keras.layers.Dense(340)\n",
    "            ]\n",
    "        )\n",
    "        self.decoder = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.InputLayer(input_shape=(1,170,1,1)),\n",
    "                tf.keras.layers.Dense(5440),\n",
    "                tf.keras.layers.Reshape((1,170,32,1)),\n",
    "                tf.keras.layers.BatchNormalization(momentum=0.9),\n",
    "                tf.keras.layers.Conv2DTranspose(\n",
    "                    filters=128, \n",
    "                    strides=2,\n",
    "                    kernel_size=14, \n",
    "                    padding='same',\n",
    "                    activation='relu'), #layer 1 finish\n",
    "                tf.keras.layers.BatchNormalization(momentum=0.9),\n",
    "                tf.keras.layers.Conv2DTranspose(\n",
    "                    filters=64, \n",
    "                    strides=1,\n",
    "                    kernel_size=14, \n",
    "                    padding='same',\n",
    "                    activation='relu'), #layer 2 finish\n",
    "                tf.keras.layers.BatchNormalization(momentum=0.9),\n",
    "                tf.keras.layers.Conv2DTranspose(\n",
    "                    filters=32, \n",
    "                    strides=2,\n",
    "                    kernel_size=28, \n",
    "                    padding='same',\n",
    "                    activation='relu'), #layer 3 finish\n",
    "                tf.keras.layers.BatchNormalization(momentum=0.9),\n",
    "                tf.keras.layers.Conv2DTranspose(\n",
    "                    filters=16, \n",
    "                    strides=2,\n",
    "                    kernel_size=56, \n",
    "                    padding='same',\n",
    "                    activation='relu'), #layer 4 finish\n",
    "                tf.keras.layers.BatchNormalization(momentum=0.9),\n",
    "                tf.keras.layers.Conv2DTranspose(\n",
    "                    filters=1, \n",
    "                    strides=1,\n",
    "                    kernel_size=56, \n",
    "                    padding='same') #layer 5 finish\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        \n",
    "    @tf.function\n",
    "    def sample(self, eps=None):\n",
    "        if eps is None:\n",
    "            eps = tf.random.normal(shape=(100,self.latent_dim))\n",
    "        return self.decode(eps, apply_sigmoid=True)\n",
    "    \n",
    "    def encode(self, x):\n",
    "        mean, logvar = tf.split(self.encoder(x), num_or_size_splits=2, axis=1)\n",
    "        return mean, logvar\n",
    "    \n",
    "    def reparameterize(self, mean, logvar):\n",
    "        eps = tf.random.normal(shape=mean.shape)\n",
    "        return eps * tf.exp(logvar * 0.5) + mean\n",
    "    \n",
    "    def decode(self, z, apply_sigmoid=False):\n",
    "        logits = self.decoder(z)\n",
    "        if apply_sigmoid:\n",
    "            probs = tf.sigmoid(logits)\n",
    "            return probs\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be49a019",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CVAE_Small(tf.keras.Model):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(CVAE_Small, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.encoder = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.InputLayer(input_shape=(1,1360,1)),\n",
    "                tf.keras.layers.Conv2D(\n",
    "                    filters=128,\n",
    "                    kernel_size=28, #decided by doing input_dim / 9; similar to keras documentation\n",
    "#                     strides=2, \n",
    "                    dilation_rate=2,\n",
    "                    activation='relu'), \n",
    "                tf.keras.layers.BatchNormalization(momentum=0.9), #layer 1 finish\n",
    "                tf.keras.layers.Conv2D(\n",
    "                    filters=64,\n",
    "                    kernel_size=14, \n",
    "#                     strides=2, \n",
    "                    dilation_rate=2,\n",
    "                    activation='relu'),\n",
    "                tf.keras.layers.BatchNormalization(momentum=0.9), #layer 2 finish\n",
    "                tf.keras.layers.Conv2D(\n",
    "                    filters=32,\n",
    "                    kernel_size=7, \n",
    "#                     strides=2,\n",
    "                    dilation_rate=2,\n",
    "                    activation='relu'),\n",
    "                tf.keras.layers.BatchNormalization(momentum=0.9), #layer 3 finish\n",
    "                tf.keras.layers.Conv2D(\n",
    "                    filters=16,\n",
    "                    kernel_size=14, \n",
    "#                     strides=2,\n",
    "                    dilation_rate=2,\n",
    "                    activation='relu'),\n",
    "                tf.keras.layers.BatchNormalization(momentum=0.9), #layer 4 finish\n",
    "                tf.keras.layers.Dense(340),\n",
    "                tf.keras.layers.Dense(170)\n",
    "            ]\n",
    "        )\n",
    "        self.decoder = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.InputLayer(input_shape=(85,1)),\n",
    "                tf.keras.layers.Dense(2720),\n",
    "                tf.keras.layers.Reshape((1,85,32)),\n",
    "                tf.keras.layers.BatchNormalization(momentum=0.9),\n",
    "                tf.keras.layers.Conv2DTranspose(\n",
    "                    filters=128, \n",
    "                    strides=2,\n",
    "                    kernel_size=14, \n",
    "                    padding='same',\n",
    "                    activation='relu'), #layer 1 finish\n",
    "                tf.keras.layers.BatchNormalization(momentum=0.9),\n",
    "                tf.keras.layers.Conv2DTranspose(\n",
    "                    filters=64, \n",
    "                    strides=2,\n",
    "                    kernel_size=14, \n",
    "                    padding='same',\n",
    "                    activation='relu'), #layer 2 finish\n",
    "                tf.keras.layers.BatchNormalization(momentum=0.9),\n",
    "                tf.keras.layers.Conv2DTranspose(\n",
    "                    filters=32, \n",
    "                    strides=2,\n",
    "                    kernel_size=28, \n",
    "                    padding='same',\n",
    "                    activation='relu'), #layer 3 finish\n",
    "                tf.keras.layers.BatchNormalization(momentum=0.9),\n",
    "                tf.keras.layers.Conv2DTranspose(\n",
    "                    filters=16, \n",
    "                    strides=2,\n",
    "                    kernel_size=56, \n",
    "                    padding='same',\n",
    "                    activation='relu'), #layer 4 finish\n",
    "                tf.keras.layers.BatchNormalization(momentum=0.9),\n",
    "                tf.keras.layers.Conv2DTranspose(\n",
    "                    filters=1, \n",
    "                    strides=1,\n",
    "                    kernel_size=56, \n",
    "                    padding='same') #layer 5 finish\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        \n",
    "    @tf.function\n",
    "    def sample(self, eps=None):\n",
    "        if eps is None:\n",
    "            eps = tf.random.normal(shape=(100,self.latent_dim))\n",
    "        return self.decode(eps, apply_sigmoid=True)\n",
    "    \n",
    "    def encode(self, x):\n",
    "        mean, logvar = tf.split(self.encoder(x), num_or_size_splits=2, axis=1)\n",
    "        return mean, logvar\n",
    "    \n",
    "    def reparameterize(self, mean, logvar):\n",
    "        eps = tf.random.normal(shape=mean.shape)\n",
    "        return eps * tf.exp(logvar * 0.5) + mean\n",
    "    \n",
    "    def decode(self, z, apply_sigmoid=False):\n",
    "        logits = self.decoder(z)\n",
    "        if apply_sigmoid:\n",
    "            probs = tf.sigmoid(logits)\n",
    "            return probs\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914db873",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfba7a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c53bf5bf",
   "metadata": {},
   "source": [
    "# VAE w Pytorch\n",
    "https://towardsdatascience.com/variational-autoencoder-demystified-with-pytorch-implementation-3a06bee395ed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f637300",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils\n",
    "import torch.distributions\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt; plt.rcParams['figure.dpi'] = 200\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ad1648",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(_x_):\n",
    "    return np.maximum(0, _x_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a6ede0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariationalEncoder(nn.Module):\n",
    "    def __init__(self, latent_dims):\n",
    "#         find INPUT_SIZE\n",
    "        super(VariationalEncoder, self).__init__()\n",
    "        self.layer1 = nn.Conv2D(input_size, 256, stride=2)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.norm1 = nn.BatchNorm2d(256, momentum=0.9)\n",
    "        self.layer2 = nn.Conv2D(256, 128, stride=2)\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.norm2 = nn.BatchNorm2d(128, momentum=0.9)\n",
    "        self.layer3 = nn.Conv2D(128, 64, stride=2)\n",
    "        self.act3 = nn.ReLU()\n",
    "        self.norm3 = nn.BatchNorm2d(64, momentum=0.9)\n",
    "\n",
    "\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        self.linear1 = nn.Linear(784, 512)\n",
    "        self.linear2 = nn.Linear(512, latent_dims)\n",
    "        self.linear3 = nn.Linear(512, latent_dims)\n",
    "\n",
    "        self.N = torch.distributions.Normal(0, 1)\n",
    "        self.N.loc = self.N.loc.cuda() # hack to get sampling on the GPU\n",
    "        self.N.scale = self.N.scale.cuda()\n",
    "        self.kl = 0\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = F.relu(self.linear1(x))\n",
    "        mu =  self.linear2(x)\n",
    "        sigma = torch.exp(self.linear3(x))\n",
    "        z = mu + sigma*self.N.sample(mu.shape)\n",
    "        self.kl = (sigma**2 + mu**2 - torch.log(sigma) - 1/2).sum()\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e821a7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dims):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.linear1 = nn.Linear(latent_dims, 512)\n",
    "        self.linear2 = nn.Linear(512, 784)\n",
    "\n",
    "    def forward(self, z):\n",
    "        z = F.relu(self.linear1(z))\n",
    "        z = torch.sigmoid(self.linear2(z))\n",
    "        return z.reshape((-1, 1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e27350",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariationalAutoencoder(nn.Module):\n",
    "    def __init__(self, latent_dims):\n",
    "        super(VariationalAutoencoder, self).__init__()\n",
    "        self.encoder = VariationalEncoder(latent_dims)\n",
    "        self.decoder = Decoder(latent_dims)\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        return self.decoder(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01514509",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(autoencoder, data, epochs=20):\n",
    "    opt = torch.optim.Adam(autoencoder.parameters())\n",
    "    for epoch in range(epochs):\n",
    "        for x, y in data:\n",
    "            x = x.to(device) # GPU\n",
    "            opt.zero_grad()\n",
    "            x_hat = autoencoder(x)\n",
    "            loss = ((x - x_hat)**2).sum() + autoencoder.encoder.kl\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a36adec",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VariationalAutoencoder(latent_dims).to(device) # GPU\n",
    "vae = train(vae, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91753b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_latent(vae, data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
